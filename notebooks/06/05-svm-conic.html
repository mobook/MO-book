
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Extra material: Support Vector Machines with conic optimization &#8212; Companion code for the book &#34;Hands-On Mathematical Optimization with Python&#34;</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-DVQ7NZ8CYZ"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-DVQ7NZ8CYZ');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-DVQ7NZ8CYZ');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/06/05-svm-conic';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Extra material: Luenberger’s Investment Wheel" href="06-investment-wheel.html" />
    <link rel="prev" title="6.4 Optimal Design of Multilayered Building Insulation" href="04-building-insulation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/cover.jpg" class="logo__image only-light" alt="Companion code for the book "Hands-On Mathematical Optimization with Python" - Home"/>
    <script>document.write(`<img src="../../_static/cover.jpg" class="logo__image only-dark" alt="Companion code for the book "Hands-On Mathematical Optimization with Python" - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Hands-On Mathematical Optimization with Python
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../01/01.00.html">1. Mathematical Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../01/01-production-planning.html">1.1 A first production planning problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/02-production-planning-basic.html">1.2 A basic Pyomo model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01/03-production-planning-advanced.html">1.3 A data-driven Pyomo Model</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../02/02.00.html">2. Linear Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../02/01-bim.html">2.1 BIM production planning using linear optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/02-lad-regression.html">2.2 Least Absolute Deviation (LAD) Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/03-mad-portfolio-optimization.html">2.3 Mean Absolute Deviation (MAD) portfolio optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/04-bim-maxmin.html">2.4 BIM production for worst case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/05-bim-fractional.html">2.5 BIM production variants</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/06-bim-dual.html">2.6 Dual of the BIM production problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/07-bim-demand-forecast.html">2.7 BIM production using demand forecasts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/08-L1-regression-wine-quality.html">Extra material: Wine quality prediction with <span class="math notranslate nohighlight">\(L_1\)</span> regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02/09-production-facility-worst-case.html">Extra material: Multi-product facility production</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../03/03.00.html">3. Mixed Integer Linear Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../03/01-bim-perturbed.html">3.1 BIM production with perturbed data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/02-shift-scheduling.html">3.2 Workforce shift scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/03-recharging-electric-vehicle.html">3.3 Recharging strategy for an electric vehicle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/04-simple-production-model-gdp.html">3.4 Production model using disjunctions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/05-machine-scheduling.html">3.5 Machine Scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/06-facility-location.html">3.6 Facility location problem</a></li>


<li class="toctree-l2"><a class="reference internal" href="../03/07-bim-production-revisited.html">3.7 BIM production revisited</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/08-cryptarithms.html">Extra material: Cryptarithms puzzle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/09-strip-packing.html">Extra material: Strip packing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/10-job-shop-scheduling.html">Extra material: Job shop scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03/11-maintenance-planning.html">Extra material: Maintenance planning</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../04/04.00.html">4. Network Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../04/01-dinner-seat-allocation.html">4.1 Dinner seating arrangement</a></li>

<li class="toctree-l2"><a class="reference internal" href="../04/02-mincost-flow.html">4.2 Minimum-Cost Flow Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/03-gasoline-distribution.html">4.3 Gasoline distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/04-exam-room-scheduling.html">4.4 Exam room scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/05-cryptocurrency-arbitrage.html">4.5 Cryptocurrency arbitrage search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/06-power-network.html">Extra material: Energy dispatch problem</a></li>



<li class="toctree-l2"><a class="reference internal" href="../04/07-forex-arbitrage.html">Extra material: Forex Arbitrage</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/08-traveling-salesman-problem.html">Extra material: Traveling Salesman Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04/09-shortest-path-road-networks.html">Extra material: Shortest path problem in real life</a></li>


</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../05/05.00.html">5. Convex Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../05/01-milk-pooling.html">5.1 Milk pooling and blending</a></li>
<li class="toctree-l2"><a class="reference internal" href="../05/02-ols-regression.html">5.2 Ordinary Least Squares (OLS) Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../05/03-markowitz-portfolio.html">5.3 Markowitz portfolio optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../05/04-svm-binary-classification.html">5.4 Support Vector Machines for binary classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../05/05-refinery-production.html">Extra material: Refinery production and shadow pricing with CVXPY</a></li>
<li class="toctree-l2"><a class="reference internal" href="../05/06-cutting-stock.html">Extra Material: Cutting Stock</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="06.00.html">6. Conic Optimization</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01-economic-order-quantity.html">6.1 Economic Order Quantity</a></li>
<li class="toctree-l2"><a class="reference internal" href="02-kelly-criterion.html">6.2 The Kelly criterion</a></li>
<li class="toctree-l2"><a class="reference internal" href="03-markowitz-portfolio-revisited.html">6.3 Markowitz portfolio optimization revisited</a></li>
<li class="toctree-l2"><a class="reference internal" href="04-building-insulation.html">6.4 Optimal Design of Multilayered Building Insulation</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Extra material: Support Vector Machines with conic optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="06-investment-wheel.html">Extra material: Luenberger’s Investment Wheel</a></li>
<li class="toctree-l2"><a class="reference internal" href="07-optimal-growth-portfolios.html">Extra material: Optimal Growth Portfolios with Risk Aversion</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../07/07.00.html">7. Accounting for Uncertainty: Optimization Meets Reality</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../07/01-fleet-assignment.html">7.1 Fleet assignment problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../07/02-bim-robustness-analysis.html">7.2 Robustness analysis of BIM production plan via simulations</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../08/08.00.html">8. Robust Optimization - Single Stage Problems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../08/01-bim-robust-optimization.html">8.1 Robust BIM microchip production problem</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../09/09.00.html">9. Stochastic Optimization - Single Stage Problems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../09/01-markowitz-portfolio-with-chance-constraint.html">9.1 Markowitz portfolio optimization with chance constraints</a></li>
<li class="toctree-l2"><a class="reference internal" href="../09/02-pop-up-shop.html">9.2 Pop-up shop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../09/03-seafood-distribution-center.html">9.3 Stock optimization for seafood distribution center</a></li>
<li class="toctree-l2"><a class="reference internal" href="../09/04-economic-dispatch.html">9.4 Economic dispatch in renewable energy systems using chance constraints</a></li>

</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../10/10.00.html">10. Two-Stage Problems</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../10/01-aircraft-seat-allocation.html">10.1 Aircraft seat allocation problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10/02-two-stage-production-planning.html">10.2 Two-stage production planning using constraint and column generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10/03-opf-linear-decision-rule.html">10.3 Optimal power flow problem with recourse actions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10/04-farmer-problem.html">Extra: The farmer’s problem and its variants</a></li>
<li class="toctree-l2"><a class="reference internal" href="../10/05-opf-wind-curtailment.html">Extra: Two-stage energy dispatch optimization with wind curtailment</a></li>

</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendix/appendix.html">Appendix: Working with Pyomo</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix/pyomo-style-guide.html">Pyomo style guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/functional-programming-pyomo.html">Functional Programming with Pyomo</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/mobook/MO-book/blob/main/notebooks/06/05-svm-conic.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/mobook/MO-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/mobook/MO-book/issues/new?title=Issue%20on%20page%20%2Fnotebooks/06/05-svm-conic.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/notebooks/06/05-svm-conic.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Extra material: Support Vector Machines with conic optimization</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preamble-install-pyomo-and-a-solver">Preamble: Install Pyomo and a solver</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-set">The Data Set</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#read-data">Read data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#select-features-and-training-sets">Select features and training sets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-metrics">Performance metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conic-optimization-model">Conic optimization model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#primal-formulation">Primal formulation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dual-formulation">Dual formulation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyomo-implementation">Pyomo implementation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kernelized-svm">Kernelized SVM</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nonlinear-feature-spaces">Nonlinear feature spaces</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-kernel-trick">The kernel trick</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-kernel">Linear kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#radial-basis-function-kernel">Radial basis function kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-kernel">Polynomial kernel</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="extra-material-support-vector-machines-with-conic-optimization">
<span id="index-5"></span><span id="index-4"></span><span id="index-3"></span><span id="index-2"></span><span id="index-1"></span><span id="index-0"></span><h1>Extra material: Support Vector Machines with conic optimization<a class="headerlink" href="#extra-material-support-vector-machines-with-conic-optimization" title="Link to this heading">#</a></h1>
<p>In this notebook we come back to the concept of training support vector machines as we did in <a class="reference internal" href="../05/04-svm-binary-classification.html"><span class="std std-doc">the first SVM notebook</span></a></p>
<p>The difference is that we shall now be solving the dual problems related to training the SVM’s using the conic quadratic optimization by explicitly calling the Mosek solver, which should yield more stable numerical results than general convex optimization.</p>
<p>The first part of this notebook shall therefore consist of data imports and other things that need no further explanation. Please move directly to the cell entitled “Conic optimization model” if you already have the data loaded from there.</p>
<p>Point of attention: An important difference with the first notebook will be the fact that we will eliminate the ‘intercept’ <span class="math notranslate nohighlight">\(b\)</span> of the SVM to keep our equations simple.</p>
<section id="preamble-install-pyomo-and-a-solver">
<h2>Preamble: Install Pyomo and a solver<a class="headerlink" href="#preamble-install-pyomo-and-a-solver" title="Link to this heading">#</a></h2>
<p>This cell selects and verifies a global SOLVER for the notebook. If run on Google Colab, the cell installs Pyomo and ipopt, then sets SOLVER to use the ipopt solver. If run elsewhere, it assumes Pyomo and the Mosek solver have been previously installed and sets SOLVER to use the Mosek solver via the Pyomo SolverFactory. It then verifies that SOLVER is available.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span><span class="o">,</span><span class="w"> </span><span class="nn">os</span>

<span class="k">if</span> <span class="s1">&#39;google.colab&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">:</span>
    <span class="o">%</span><span class="k">pip</span> install idaes-pse --pre &gt;/dev/null 2&gt;/dev/null
    <span class="o">!</span>idaes<span class="w"> </span>get-extensions<span class="w"> </span>--to<span class="w"> </span>./bin<span class="w"> </span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;PATH&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="s1">&#39;:bin&#39;</span>
    <span class="n">solver</span> <span class="o">=</span> <span class="s2">&quot;ipopt&quot;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">solver</span> <span class="o">=</span> <span class="s2">&quot;mosek_direct&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">pyomo.kernel</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pmo</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyomo.environ</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pyo</span> 
<span class="n">SOLVER</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">SolverFactory</span><span class="p">(</span><span class="n">solver</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">SOLVER</span><span class="o">.</span><span class="n">available</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;Solver </span><span class="si">{</span><span class="n">solver</span><span class="si">}</span><span class="s2"> is not available.&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-data-set">
<h2>The Data Set<a class="headerlink" href="#the-data-set" title="Link to this heading">#</a></h2>
<p>The following data set contains data from a collection of known genuine and known counterfeit banknote specimens. The data includes four continuous statistical measures obtained from the wavelet transform of banknote images named “variance”, “skewness”, “curtosis”, and “entropy”, and a binary variable named “class” which is 0 if genuine and 1 if counterfeit.</p>
<p><a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/banknote+authentication">https://archive.ics.uci.edu/ml/datasets/banknote+authentication</a></p>
<section id="read-data">
<h3>Read data<a class="headerlink" href="#read-data" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># read data set</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;https://raw.githubusercontent.com/mobook/MO-book/main/datasets/data_banknote_authentication.txt&quot;</span><span class="p">,</span>
    <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">,</span> <span class="s2">&quot;curtosis&quot;</span><span class="p">,</span> <span class="s2">&quot;entropy&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Banknotes&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="select-features-and-training-sets">
<h3>Select features and training sets<a class="headerlink" href="#select-features-and-training-sets" title="Link to this heading">#</a></h3>
<p>Following customary practices, we divide the data set into a <strong>training set</strong> used to trail the classifier, and a <strong>testing set</strong> that will be used to evaluate the performance of the classifier. In addition, we select two dimensional subset of the features to enable plotting of the results for exposition. Since our definition of a positive outcome corresponds to detecting a genuine banknote, we rescale the “class” feature to have values of 1 for genuine banknotes and -1 for counterfeit banknotes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create training and validation test sets</span>
<span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># select training features</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;variance&quot;</span><span class="p">,</span> <span class="s2">&quot;skewness&quot;</span><span class="p">]</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># separate into features and outputs</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>The following cell presents a simple function to create a scatter plot for a labeled 2D set of features. The function assigns default labels and colors, and passes along other keyword arguments.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">scatter_labeled_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;+1&quot;</span><span class="p">,</span> <span class="s2">&quot;-1&quot;</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="c1"># Prepend keyword arguments for all scatter plots</span>
    <span class="n">kw</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;kind&quot;</span><span class="p">:</span> <span class="s2">&quot;scatter&quot;</span><span class="p">,</span> <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">}</span>
    <span class="n">kw</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Ignore warnings from matplotlib scatter plot</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
        <span class="n">kw</span><span class="p">[</span><span class="s2">&quot;ax&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kw</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>


<span class="c1"># plot training and test sets in two axes</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">scatter_labeled_data</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">y_train</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;genuine&quot;</span><span class="p">,</span> <span class="s2">&quot;counterfeit&quot;</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Training Set&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">scatter_labeled_data</span><span class="p">(</span>
    <span class="n">X_test</span><span class="p">,</span>
    <span class="n">y_test</span><span class="p">,</span>
    <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;genuine&quot;</span><span class="p">,</span> <span class="s2">&quot;counterfeit&quot;</span><span class="p">],</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Test Set&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/de549641391a265d70f3d6eddc624bf39241bacd6cc00afffe17905c1384a24e.png" src="../../_images/de549641391a265d70f3d6eddc624bf39241bacd6cc00afffe17905c1384a24e.png" />
</div>
</div>
</section>
<section id="performance-metrics">
<h3>Performance metrics<a class="headerlink" href="#performance-metrics" title="Link to this heading">#</a></h3>
<p>The accuracy score alone is not always a reliable metric for evaluating the performance of binary classifiers. For instance, when one outcome is significantly more frequent than the other, a classifier that always predicts the more common outcome without regard to the feature vector can achieve a very high accuracy score while being completely wrong on the less common outcome.</p>
<p>Moreover, in many applications, the consequences of a false positive can differ from those of a false negative. For these reasons, we seek a more comprehensive set of metrics to compare binary classifiers.</p>
<ul class="simple">
<li><p>Sensitivity of a classifier measures how many of the actually positive items in the dataset have been labelled as positive.</p></li>
<li><p>Precision, on the other hand, counts how many of the items marked as positive, are actually positive.</p></li>
</ul>
<p>A <a class="reference external" href="https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7">detailed discussion on this topic</a> recommends the <a class="reference external" href="https://towardsdatascience.com/the-best-classification-metric-youve-never-heard-of-the-matthews-correlation-coefficient-3bf50a2f3e9a">Matthews correlation coefficient (MCC)</a> as a reliable performance measure for binary classifiers.</p>
<p>The code below demonstrates an example of a function that evaluates the performance of a binary classifier and returns the Matthews correlation coefficient as its output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">validate</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="c1"># Calculate the elements of the confusion matrix</span>
    <span class="n">true_positives</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">false_negatives</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">false_positives</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">true_negatives</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">true_positives</span> <span class="o">+</span> <span class="n">true_negatives</span> <span class="o">+</span> <span class="n">false_positives</span> <span class="o">+</span> <span class="n">false_negatives</span>

    <span class="c1"># Calculate the Matthews correlation coefficient (MCC)</span>
    <span class="n">mcc_numerator</span> <span class="o">=</span> <span class="p">(</span><span class="n">true_positives</span> <span class="o">*</span> <span class="n">true_negatives</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span>
        <span class="n">false_positives</span> <span class="o">*</span> <span class="n">false_negatives</span>
    <span class="p">)</span>
    <span class="n">mcc_denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
        <span class="p">(</span><span class="n">true_positives</span> <span class="o">+</span> <span class="n">false_positives</span><span class="p">)</span>
        <span class="o">*</span> <span class="p">(</span><span class="n">true_positives</span> <span class="o">+</span> <span class="n">false_negatives</span><span class="p">)</span>
        <span class="o">*</span> <span class="p">(</span><span class="n">true_negatives</span> <span class="o">+</span> <span class="n">false_positives</span><span class="p">)</span>
        <span class="o">*</span> <span class="p">(</span><span class="n">true_negatives</span> <span class="o">+</span> <span class="n">false_negatives</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">mcc</span> <span class="o">=</span> <span class="n">mcc_numerator</span> <span class="o">/</span> <span class="n">mcc_denominator</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Matthews correlation coefficient (MCC) = </span><span class="si">{</span><span class="n">mcc</span><span class="si">:</span><span class="s2">0.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># report sensitivity and precision, and accuracy</span>
        <span class="n">sensitivity</span> <span class="o">=</span> <span class="n">true_positives</span> <span class="o">/</span> <span class="p">(</span><span class="n">true_positives</span> <span class="o">+</span> <span class="n">false_negatives</span><span class="p">)</span>
        <span class="n">precision</span> <span class="o">=</span> <span class="n">true_positives</span> <span class="o">/</span> <span class="p">(</span><span class="n">true_positives</span> <span class="o">+</span> <span class="n">false_positives</span><span class="p">)</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">true_positives</span> <span class="o">+</span> <span class="n">true_negatives</span><span class="p">)</span> <span class="o">/</span> <span class="n">total</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sensitivity = </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">sensitivity</span><span class="si">:</span><span class="s2"> 0.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision = </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">precision</span><span class="si">:</span><span class="s2"> 0.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy = </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">accuracy</span><span class="si">:</span><span class="s2"> 0.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

        <span class="c1"># Display the binary confusion matrix</span>
        <span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="p">[</span><span class="n">true_positives</span><span class="p">,</span> <span class="n">false_negatives</span><span class="p">],</span>
                <span class="p">[</span><span class="n">false_positives</span><span class="p">,</span> <span class="n">true_negatives</span><span class="p">],</span>
            <span class="p">],</span>
            <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Actual Positive&quot;</span><span class="p">,</span> <span class="s2">&quot;Actual Negative&quot;</span><span class="p">],</span>
            <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Predicted Positive&quot;</span><span class="p">,</span> <span class="s2">&quot;Predicted Negative&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">display</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mcc</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="conic-optimization-model">
<h2>Conic optimization model<a class="headerlink" href="#conic-optimization-model" title="Link to this heading">#</a></h2>
<section id="primal-formulation">
<h3>Primal formulation<a class="headerlink" href="#primal-formulation" title="Link to this heading">#</a></h3>
<p>As already explained in in <a class="reference internal" href="#../05/svm.ipynb"><span class="xref myst">the first support vector machine notebook</span></a>, the standard formulation of a linear support vector machine uses training sets with <span class="math notranslate nohighlight">\(p\)</span>-element feature vectors <span class="math notranslate nohighlight">\(x_i\in\mathbb{R}^p\)</span> along with classification labels for those vectors, <span class="math notranslate nohighlight">\(y_i = \pm 1\)</span>. A classifier is defined by two parameters: a weight vector <span class="math notranslate nohighlight">\(w\in\mathbb{R}^p\)</span> and a bias term <span class="math notranslate nohighlight">\(b\in\mathbb{R}\)</span></p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
     y^{pred} &amp; = \text{sgn}(w^\top x + b)
\end{align*}
\]</div>
<p>We train the classifier by developing and solving an optimization model for the values of <span class="math notranslate nohighlight">\(w\)</span> and <span class="math notranslate nohighlight">\(b\)</span>. The presence of parameter <span class="math notranslate nohighlight">\(b\)</span>, however, unnecessarily complicates the presentation and derivation of the model. To simplify, we introduce an augmented feature vector <span class="math notranslate nohighlight">\(\bar{x} = (1, x) \in \mathbb{R}^{p+1}\)</span> and an augmented weight vector <span class="math notranslate nohighlight">\(\bar{w} = (b, w) \in \mathbb{R}^{p+1}\)</span> so the classifier can be presented as</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y^{pred} &amp; = \text{sgn}(\bar{w}^\top \bar{x})
\end{align*}
\]</div>
<p>Given a value of <span class="math notranslate nohighlight">\(\bar{w}\)</span>, there is a family of hyperplanes in <span class="math notranslate nohighlight">\(\mathbb{R}^{p+1}\)</span> orthogonal to <span class="math notranslate nohighlight">\(\bar{w}\)</span>. A <strong>separating hyperplane</strong>, if one exists, separates all data points with <span class="math notranslate nohighlight">\(y_i = 1\)</span> from those with <span class="math notranslate nohighlight">\(y_i = -1\)</span>. The distance between <span class="math notranslate nohighlight">\(\bar{x}_i\)</span> and the separating  hyperplane is the length of the projection <span class="math notranslate nohighlight">\(\bar{x}_i\)</span> onto <span class="math notranslate nohighlight">\(\bar{w}\)</span>, which is</p>
<div class="math notranslate nohighlight">
\[\frac{\bar{w}^\top \bar{x}_i}{\|\bar{w}\|}\]</div>
<p>If a separating hyperplane exists, then we can choose the norm of <span class="math notranslate nohighlight">\(\bar{w}\)</span> so that a hard-margin classifier exists for the training set <span class="math notranslate nohighlight">\((\bar{x}_i, y_i)\)</span> where</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y_i \bar{w}^\top \bar{x}_i &amp; \geq 1 &amp; \forall i \in 1, 2, \dots, n
\end{align*}
\]</div>
<p>Otherwise, if a separating hyperplane does not exist, we introduce non-negative slack variables <span class="math notranslate nohighlight">\(z_i\)</span> to relax the constraints and settle for a soft-margin classifier</p>
<div class="math notranslate nohighlight">
\[
\begin{align*}
y_i \bar{w}^\top \bar{x}_i &amp; \geq 1 - z_i&amp; \forall i \in 1, 2, \dots, n
\end{align*}
\]</div>
<p>Given <span class="math notranslate nohighlight">\(\bar{w}\)</span>, training data for which <span class="math notranslate nohighlight">\(z_i &gt; 1\)</span> are misclassified. The training objective is to minimize the number and distance to misclassified data points. This leads to the optimization problem</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min \quad &amp; \frac{1}{2} \|\bar{w}\|_2^2 + \frac{c}{n}\sum_{i=1}^n z_i \\
\text{s.t.} \quad &amp; z_i \geq 1 - y_i \bar{w}^\top \bar{x}_i &amp; \forall i = 1, 2, \dots, n \\
&amp; z_i  \geq 0 &amp; \forall i = 1, 2, \dots, n
\end{align*}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\frac{1}{2} \|\bar{w}\|_2^2\)</span> is included to regularize the solution for <span class="math notranslate nohighlight">\(\bar{w}\)</span>. Choosing larger values of <span class="math notranslate nohighlight">\(c\)</span> will reduce the number and size of misclassifications. The trade-off will be larger weights <span class="math notranslate nohighlight">\(\bar{w}\)</span> and the accompanying risk of over over-fitting the training data.</p>
<p>To simplify the presentation of the model, we introduce an <span class="math notranslate nohighlight">\(n \times (p+1)\)</span> matrix <span class="math notranslate nohighlight">\(F\)</span> constructed from the training data</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
    F &amp; = \begin{bmatrix} y_1\bar{x}_1^\top \\ y_2\bar{x}_2^\top \\ \vdots \\ y_n\bar{x}_n^\top \end{bmatrix}
\end{align}
\end{split}\]</div>
<p>Next we introduce a <strong><a class="reference external" href="https://docs.mosek.com/modeling-cookbook/cqo.html#equation-eq-sec-qo-modeling-qset2">rotated quadratic cone</a></strong> defined as</p>
<div class="math notranslate nohighlight">
\[\mathcal{Q}^m_r = \{u\in\mathbb{R}^m | 2u_1u_2 \geq u_3^2 + \cdots + u_m^2,\ u_1, u_2 \geq 0 \}\]</div>
<p>and parameter <span class="math notranslate nohighlight">\(r\)</span> where</p>
<div class="math notranslate nohighlight">
\[2 r \geq \|\bar{w}\|_2^2 = \bar{w}_1^2 + \bar{w}_2^2 + \cdots + \bar{w}_{p+1}^2\]</div>
<p>With these additional components, the primal problem is now a conic optimization problem ready for implementation with the Pyomo <a class="reference external" href="https://pyomo.readthedocs.io/en/stable/library_reference/kernel/index.html">Kernel Library</a> and Mosek conic solver.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
    \min \quad &amp; r + \frac{c}{n} 1^\top z\\
    \text{s.t.}\quad &amp; (r, 1, \bar{w}) \in \mathcal{Q}_r^{3 + p} \\
    &amp; z + F \bar{w} \geq 1  \\
    &amp; z \geq 0 &amp; z\in\mathbb{R}^n \\
    &amp; r\in\mathbb{R} \\
\end{align*}
\end{split}\]</div>
<p>Like for the previous case, the Pyomo implementation is a “factory” function that returns a linear SVM.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linear Support Vector Machine (SVM) class</span>
<span class="k">class</span><span class="w"> </span><span class="nc">LinearSvm</span><span class="p">:</span>
    <span class="c1"># Initialize the Linear SVM with weights and bias</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

    <span class="c1"># Call method to compute the decision function</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>

    <span class="c1"># Representation method for the Linear SVM class</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;LinearSvm(w = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span><span class="si">}</span><span class="s2">, b = </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="si">}</span><span class="s2">)&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">conicSvmFactory</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># create data matrix F</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
        <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
    <span class="p">)</span>  <span class="c1"># Appending 1&#39;s to features</span>

    <span class="c1"># create model block</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">block</span><span class="p">()</span>

    <span class="c1"># decision variables</span>
    <span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>

    <span class="c1"># objective</span>
    <span class="n">m</span><span class="o">.</span><span class="n">primal</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">expr</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">+</span> <span class="p">(</span><span class="n">c</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">))</span>

    <span class="c1"># constraints</span>
    <span class="n">m</span><span class="o">.</span><span class="n">qr</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">conic</span><span class="o">.</span><span class="n">rotated_quadratic</span><span class="o">.</span><span class="n">as_domain</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint_list</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">pmo</span><span class="o">.</span><span class="n">constraint</span><span class="p">(</span>
                <span class="n">body</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">lb</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># solve</span>
    <span class="n">SOLVER</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="c1"># return svm</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]()</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]()</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)})</span>

    <span class="k">return</span> <span class="n">LinearSvm</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>


<span class="n">svm_v2</span> <span class="o">=</span> <span class="n">conicSvmFactory</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">svm_v2</span><span class="o">.</span><span class="n">w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">svm_v2</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>variance    0.546234
skewness    0.152174
dtype: float64
-0.21435828724315473
</pre></div>
</div>
</div>
</div>
<p>The following cell with reveal the performance of this standard SVM.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">scatter_comparison</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
    <span class="n">xmax</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">xlim</span> <span class="o">=</span> <span class="p">[</span><span class="n">xmin</span> <span class="o">-</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="p">(</span><span class="n">xmax</span> <span class="o">-</span> <span class="n">xmin</span><span class="p">),</span> <span class="n">xmax</span> <span class="o">+</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="p">(</span><span class="n">xmax</span> <span class="o">-</span> <span class="n">xmin</span><span class="p">)]</span>
    <span class="n">ylim</span> <span class="o">=</span> <span class="p">[</span><span class="n">ymin</span> <span class="o">-</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="p">(</span><span class="n">ymax</span> <span class="o">-</span> <span class="n">ymin</span><span class="p">),</span> <span class="n">ymax</span> <span class="o">+</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="p">(</span><span class="n">ymax</span> <span class="o">-</span> <span class="n">ymin</span><span class="p">)]</span>

    <span class="c1"># Plot training and test sets</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;genuine&quot;</span><span class="p">,</span> <span class="s2">&quot;counterfeit&quot;</span><span class="p">]</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">scatter_labeled_data</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xlim</span><span class="o">=</span><span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Actual&quot;</span>
    <span class="p">)</span>
    <span class="n">scatter_labeled_data</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">,</span>
        <span class="p">[</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">],</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">xlim</span><span class="o">=</span><span class="n">xlim</span><span class="p">,</span>
        <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Prediction&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Plot actual positives and actual negatives</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">scatter_labeled_data</span><span class="p">(</span>
        <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">y_pred</span><span class="p">[</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="s2">&quot;true positive&quot;</span><span class="p">,</span> <span class="s2">&quot;false negative&quot;</span><span class="p">],</span>
        <span class="p">[</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">],</span>
        <span class="n">xlim</span><span class="o">=</span><span class="n">xlim</span><span class="p">,</span>
        <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Actual Positives&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">scatter_labeled_data</span><span class="p">(</span>
        <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">y_pred</span><span class="p">[</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="s2">&quot;false positive&quot;</span><span class="p">,</span> <span class="s2">&quot;true negative&quot;</span><span class="p">],</span>
        <span class="p">[</span><span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;m&quot;</span><span class="p">],</span>
        <span class="n">xlim</span><span class="o">=</span><span class="n">xlim</span><span class="p">,</span>
        <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Actual Negatives&quot;</span><span class="p">,</span>
    <span class="p">)</span>


<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm_v2</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">validate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">scatter_comparison</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matthews correlation coefficient (MCC) = 0.769
Sensitivity =  91.7%
Precision =  90.6%
Accuracy =  89.1%
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Predicted Positive</th>
      <th>Predicted Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actual Positive</th>
      <td>155</td>
      <td>14</td>
    </tr>
    <tr>
      <th>Actual Negative</th>
      <td>16</td>
      <td>90</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../../_images/91ee9792ae3b637778a82f04fd7c7c2ced23bb148c236f27224c17d16f6e0417.png" src="../../_images/91ee9792ae3b637778a82f04fd7c7c2ced23bb148c236f27224c17d16f6e0417.png" />
<img alt="../../_images/bcca99a57cbfb1c0cc1efc4347e00fe5b774d7e9327e96aa15550ea19cf35294.png" src="../../_images/bcca99a57cbfb1c0cc1efc4347e00fe5b774d7e9327e96aa15550ea19cf35294.png" />
</div>
</div>
</section>
<section id="dual-formulation">
<h3>Dual formulation<a class="headerlink" href="#dual-formulation" title="Link to this heading">#</a></h3>
<p>As we already know, the dual of our problem shall be given by
$<span class="math notranslate nohighlight">\(
\begin{align*}
\min \quad &amp; \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j ( \bar{x}_i^\top \bar{x}_j ) -  \sum_{i=1}^n \alpha_i \\
\text{s.t.}\quad &amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n. \\
\end{align*}
\)</span>$</p>
<p>The symmetric <span class="math notranslate nohighlight">\(n \times n\)</span> <strong>Gram matrix</strong> is defined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    G = \begin{bmatrix} 
        (y_1\bar{x}_1^\top)(y_1\bar{x}_1) &amp; \dots &amp; (y_1\bar{x}_1^\top)(y_n\bar{x}_n) \\ 
        \vdots &amp; \ddots &amp; \vdots \\ 
        (y_n\bar{x}_n^\top)(y_1\bar{x}_1) &amp; \dots &amp; (y_n\bar{x}_n^\top)(y_n\bar{x}_n)
    \end{bmatrix}
\end{split}\]</div>
<p>where each entry is dot product of two vectors <span class="math notranslate nohighlight">\((y_i\bar{x}_i), (y_j\bar{x}_j) \in \mathbb{R}^{p+1}\)</span>.</p>
<p>Compared to the primal, the dual formulation appears to have reduced the number of decision variables from <span class="math notranslate nohighlight">\(n + p + 1\)</span> to <span class="math notranslate nohighlight">\(n\)</span>. But this has come with the penalty of introducing a dense matrix with <span class="math notranslate nohighlight">\(n^2\)</span> coefficients and potential processing time of order <span class="math notranslate nohighlight">\(n^3\)</span>. For large training sets where <span class="math notranslate nohighlight">\(n\sim 10^4-10^6\)</span> or even larger, this becomes a prohibitively expensive calculation. In addition, the Gram matrix will be rank deficient for cases <span class="math notranslate nohighlight">\(p+1 &lt; n\)</span>.</p>
<p>Reformulating the dual problem as a conic optimization problem eliminates the need to compute and store the full Gram matrix <span class="math notranslate nohighlight">\(G\)</span>. The reformulation begins by use the <span class="math notranslate nohighlight">\(n \times (p+1)\)</span> matrix <span class="math notranslate nohighlight">\(F\)</span> previously introduced in the primal problem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    F = \begin{bmatrix} y_1 \bar{x}_1^\top \\ y_2 \bar{x}_2^\top \\ \vdots \\ y_n \bar{x}_n^\top \end{bmatrix}
\end{split}\]</div>
<p>Then <span class="math notranslate nohighlight">\(G = FF^\top\)</span> and the optimization problem becomes</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min\quad &amp; \frac{1}{2} \alpha^\top F F^\top \alpha -  1^\top \alpha \\
\text{s.t.}\quad &amp; 0 \leq \alpha \leq \frac{c}{n} &amp; \alpha\in\mathbb{R}^n \\
\end{align*}
\end{split}\]</div>
<p>We introduce an additional decision variable <span class="math notranslate nohighlight">\(r \geq 0\)</span> to specify rotated quadratic cones. Let <span class="math notranslate nohighlight">\(z = F^\top\alpha\)</span>, then</p>
<div class="math notranslate nohighlight">
\[\alpha^\top F F^\top \alpha \leq 2 r \iff z^\top z \leq 2 r \iff (r, 1, z) \in Q_r^{3 + p}\]</div>
<p>The result is a conic optimization problem for the dual coefficients <span class="math notranslate nohighlight">\(\alpha\)</span> and auxiliary variables <span class="math notranslate nohighlight">\(r\)</span> and <span class="math notranslate nohighlight">\(z\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min \quad &amp; r - 1^\top \alpha\\
\text{s.t.} \quad &amp; (r, 1, z) \in \mathcal{Q}_r^{3 + p} &amp; r\in\mathbb{R} \\
&amp; z = F^\top \alpha &amp; z\in\mathbb{R}^{p+1} \\
&amp; 0 \leq \alpha \leq \frac{c}{n} &amp; \alpha\in\mathbb{R}^n \\
\end{align*}
\end{split}\]</div>
<p>The solution to dual formulation provides an alternative expression for the resulting support vector machine. Let <span class="math notranslate nohighlight">\({SV}\)</span> represent the set of <strong>support vectors</strong>, which can be implemented as the set of indices for which <span class="math notranslate nohighlight">\(\alpha_i &gt; 0\)</span>.
Then SVM can be expressed as either</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
y^{pred} &amp; = \text{sgn}\left( \bar{w}^\top \bar{x} \right)\quad
\text{where}\quad \bar{w} = \sum_{i\in\cal{SV}} \alpha_i y_i \bar{x}_i 
\end{align}
\]</div>
<p>or, more directly, as</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
y^{pred} &amp; =  \text{sgn}\left( \sum_{i\in\cal{SV}} \alpha_i y_i \bar{x}_i^\top \bar{x} \right)
\end{align}
\]</div>
<p>The first formulation is a computationally efficient implementation of a linear SVM, and used in the following Pyomo implementation. The second formulation, however, provides additional insight into how an SVM works, and is the basis for important generalizations of SVM including the kernelized SVM discussed below. Remember, we no longer need to derive the value of the primal variable <span class="math notranslate nohighlight">\(b\)</span> because we eliminated its existence by stacking 1’s into the feature vector.</p>
<p>The following code implements the above SVM dual formulation.</p>
</section>
<section id="pyomo-implementation">
<h3>Pyomo implementation<a class="headerlink" href="#pyomo-implementation" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">conicDualSVMFactory</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
        <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
    <span class="p">)</span>  <span class="c1"># Appending 1&#39;s to features</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">block</span><span class="p">()</span>

    <span class="c1"># decision variables</span>
    <span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">c</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>

    <span class="c1"># objective</span>
    <span class="n">m</span><span class="o">.</span><span class="n">o</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">expr</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">))</span>

    <span class="c1"># constraints</span>
    <span class="n">m</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint_list</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">pmo</span><span class="o">.</span><span class="n">constraint</span><span class="p">(</span><span class="n">body</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">-</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">rhs</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">conic</span><span class="o">.</span><span class="n">rotated_quadratic</span><span class="o">.</span><span class="n">as_domain</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>

    <span class="c1"># solve</span>
    <span class="n">SOLVER</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="c1"># get the support</span>
    <span class="n">S</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)]</span>

    <span class="c1"># create and return linear SVM</span>
    <span class="n">w_bar</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]()</span> <span class="o">*</span> <span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">S</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">w_bar</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)})</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">w_bar</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">y_support</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">1</span> <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]()</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)],</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    <span class="n">scatter_labeled_data</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">y_support</span><span class="p">,</span>
        <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">],</span>
        <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Support Vector&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">],</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Support Vectors&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">LinearSvm</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>


<span class="n">svm_v3</span> <span class="o">=</span> <span class="n">conicDualSVMFactory</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">svm_v3</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="n">svm_v3</span><span class="o">.</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>variance    0.546247
skewness    0.152194
dtype: float64 -0.21435778397469038
</pre></div>
</div>
<img alt="../../_images/5628e9eb2be1cefcb9064788903ce0e762681e6486d7b60435e3d9854c5877e3.png" src="../../_images/5628e9eb2be1cefcb9064788903ce0e762681e6486d7b60435e3d9854c5877e3.png" />
</div>
</div>
<p>The following cell implements the above conic dual formulation and should obtain exactly the same accuracy results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm_v3</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">validate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">scatter_comparison</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matthews correlation coefficient (MCC) = 0.769
Sensitivity =  91.7%
Precision =  90.6%
Accuracy =  89.1%
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Predicted Positive</th>
      <th>Predicted Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actual Positive</th>
      <td>155</td>
      <td>14</td>
    </tr>
    <tr>
      <th>Actual Negative</th>
      <td>16</td>
      <td>90</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../../_images/91ee9792ae3b637778a82f04fd7c7c2ced23bb148c236f27224c17d16f6e0417.png" src="../../_images/91ee9792ae3b637778a82f04fd7c7c2ced23bb148c236f27224c17d16f6e0417.png" />
<img alt="../../_images/bcca99a57cbfb1c0cc1efc4347e00fe5b774d7e9327e96aa15550ea19cf35294.png" src="../../_images/bcca99a57cbfb1c0cc1efc4347e00fe5b774d7e9327e96aa15550ea19cf35294.png" />
</div>
</div>
</section>
</section>
<section id="kernelized-svm">
<h2>Kernelized SVM<a class="headerlink" href="#kernelized-svm" title="Link to this heading">#</a></h2>
<section id="nonlinear-feature-spaces">
<h3>Nonlinear feature spaces<a class="headerlink" href="#nonlinear-feature-spaces" title="Link to this heading">#</a></h3>
<p>A linear SVM assumes the existence of a linear hyperplane that separates labeled sets of data points. Frequently, however, this is not possible and some sort of nonlinear method where the feature vector is appended with nonlinear transformations</p>
<div class="math notranslate nohighlight">
\[
\bar{x} \rightarrow \phi(\bar{x})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\phi(\bar{x})\)</span> is a function mapping <span class="math notranslate nohighlight">\(x\)</span> into a higher dimensional “feature space”. That is, <span class="math notranslate nohighlight">\(\phi : \mathbb{R}^{p + 1} \rightarrow \mathbb{R}^d\)</span> where <span class="math notranslate nohighlight">\(d \geq p +1 \)</span>. The additional dimensions may include features such as powers of the terms in <span class="math notranslate nohighlight">\(x\)</span>, or products of those terms, or other types of nonlinear transformations. In this way, the SVM has more ‘room to play’ in order to try to separate one point from another.</p>
<p>Corresponding to such a transformed vector, we have a binary classification tool given by</p>
<div class="math notranslate nohighlight">
\[
y^{pred} = \text{sgn} \left( w^\top \phi(\bar{x}) \right).
\]</div>
<p>From now onwards, the derivation of the dual problem goes exactly the same way as in the linear SVM case (please refer to <a class="reference internal" href="#../05/svm.ipynb"><span class="xref myst">the first support vector machine notebook</span></a> ), and we arrive at:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min \ &amp; \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j  \phi(\bar{x}_i)^\top \phi(\bar{x}_j) -  \sum_{i=1}^n \alpha_i \\
\text{s. t.}\quad &amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
</section>
<section id="the-kernel-trick">
<h3>The kernel trick<a class="headerlink" href="#the-kernel-trick" title="Link to this heading">#</a></h3>
<p>If you look at the optimization problem above and the corresponding classifier tool, this is an interesting situation where the separating hyperplane is embedded in a high dimensional space of nonlinear features determined by the mapping <span class="math notranslate nohighlight">\(\phi(\bar{x})\)</span>, but all we need to train the classifier and to use the classifier are the inner products  <span class="math notranslate nohighlight">\(\phi(\bar{x}_i)^\top\phi(\bar{x}_j)\)</span> and <span class="math notranslate nohighlight">\(\phi(\bar{x}_i)^\top\phi(x)\)</span>, rather than the ‘raw’ <span class="math notranslate nohighlight">\(\phi(\bar{x}_i)\)</span> and <span class="math notranslate nohighlight">\(\phi(\bar{x})\)</span> values. If we had a function <span class="math notranslate nohighlight">\(K(\bar{x}, \bar{z})\)</span> that returned the value <span class="math notranslate nohighlight">\(\phi(\bar{x})^\top\phi(\bar{z})\)</span> then we would never need to actually compute <span class="math notranslate nohighlight">\(\phi(\bar{x})\)</span>, <span class="math notranslate nohighlight">\(\phi(\bar{z})\)</span> or their inner product.</p>
<p>Mercer’s theorem turns the analysis on its head by specifying conditions for which a function <span class="math notranslate nohighlight">\(K(\bar{x}, \bar{z})\)</span> to be expressed as an inner product for some <span class="math notranslate nohighlight">\(\phi(x)\)</span>. If <span class="math notranslate nohighlight">\(K(\bar{x}, z)\)</span> is symmetric (i.e, <span class="math notranslate nohighlight">\(K(\bar{x}, \bar{z}) = K(\bar{z}, \bar{x})\)</span>, and if the Gram matrix constructed for any collection of points <span class="math notranslate nohighlight">\(x_1, x_2, \ldots, x_n\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix} 
    K(\bar{x}_1, \bar{x}_1) &amp; \dots &amp; K(\bar{x}_1, \bar{x}_n) \\ 
    \vdots &amp; \ddots &amp; \vdots \\ 
    K(\bar{x}_n, \bar{x}_1) &amp; \dots &amp; K(\bar{x}_n, \bar{x}_n) 
\end{bmatrix}
\end{split}\]</div>
<p>is positive semi-definite, then there is some <span class="math notranslate nohighlight">\(\phi(\bar{x})\)</span> for which <span class="math notranslate nohighlight">\(K(\bar{x}, \bar{z})\)</span> is an inner product. We call such functions kernels. The practical consequence is that we can train and implement nonlinear classifiers using kernel and without ever needing to compute the higher dimensional features. This remarkable result is called the “kernel trick”.</p>
</section>
<section id="implementation">
<h3>Implementation<a class="headerlink" href="#implementation" title="Link to this heading">#</a></h3>
<p>To take advantage of the kernel trick, we assume an appropriate kernel <span class="math notranslate nohighlight">\(K(\bar{x}, \bar{z})\)</span> has been identified, then replace all instances of <span class="math notranslate nohighlight">\(\phi(\bar{x_i})^\top \phi(\bar{x})\)</span> with the kernel. The “kernelized” SVM is then given by solution to</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min \ &amp; \frac{1}{2} \sum_{i=1}^n\sum_{j=1}^n \alpha_i \alpha_j y_i y_j K(\bar{x}_i, \bar{x}_j) -  \sum_{i=1}^n \alpha_i \\
\text{s. t.}\quad &amp; \alpha_i \in \left[0, \frac{c}{n}\right] &amp; i = 1, \dots, n \\
\end{align*}
\end{split}\]</div>
<p>where the resulting classifier is given by</p>
<div class="math notranslate nohighlight">
\[y^{pred} = \text{sgn} \left( \sum_{i=1}^n \alpha_iK(\bar{x}_i, \bar{x}) \right)\]</div>
<p>We define the <span class="math notranslate nohighlight">\(n\times n\)</span> positive symmetric semi-definite Gram matrix</p>
<div class="math notranslate nohighlight">
\[\begin{split}
G = \begin{bmatrix} 
    y_1 y_1 K(\bar{x}_1, \bar{x}_1) &amp; \dots &amp; y_1 y_nK(\bar{x}_1, \bar{x}_n) \\ 
    \vdots &amp; \ddots &amp; \vdots \\ 
    y_n y_1 K(\bar{x}_n, \bar{x}_1) &amp; \dots &amp; y_n y_n K(\bar{x}_n, \bar{x}_n) 
\end{bmatrix}
\end{split}\]</div>
<p>We factor <span class="math notranslate nohighlight">\(G = FF^\top\)</span> where <span class="math notranslate nohighlight">\(F\)</span> has dimensions <span class="math notranslate nohighlight">\(n \times q\)</span> and where <span class="math notranslate nohighlight">\(q\)</span> is the rank of <span class="math notranslate nohighlight">\(G\)</span>. This factorization is not unique. As demonstrated in the Python code below, one suitable factorization is the spectral factorization <span class="math notranslate nohighlight">\(G = U\Lambda U^T\)</span> where <span class="math notranslate nohighlight">\(\Lambda\)</span> is a <span class="math notranslate nohighlight">\(q\times q\)</span> diagonal matrix of non-zero eigenvalues, and <span class="math notranslate nohighlight">\(U\)</span> is an <span class="math notranslate nohighlight">\(n\times q\)</span> normal matrix such that <span class="math notranslate nohighlight">\(U^\top U = I_q\)</span>. Then</p>
<div class="math notranslate nohighlight">
\[F = U\Lambda^{1/2}\]</div>
<p>Once this factorization is complete, the optimization problem for the kernalized SVM is the same as for the linear SVM in the dual formulation</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min\quad &amp; \frac{1}{2} \alpha^\top F F^\top \alpha -  1^\top \alpha \\
\text{s.t.}\quad &amp; 0 \leq \alpha \leq \frac{c}{n} &amp; \alpha\in\mathbb{R}^n \\
\end{align*}
\end{split}\]</div>
<p>The result is a conic program for the dual coefficients <span class="math notranslate nohighlight">\(\alpha\)</span> and auxiliary variables <span class="math notranslate nohighlight">\(r\)</span> and <span class="math notranslate nohighlight">\(z\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min \quad &amp; r - 1^\top \alpha\\
\text{s.t.} \quad &amp; (r, 1, z) \in \mathcal{Q}_r^{2 + q} &amp; r\in\mathbb{R} \\
&amp; z = F^\top \alpha &amp; z\in\mathbb{R}^{q} \\
&amp; 0 \leq \alpha \leq \frac{c}{n} &amp; \alpha\in\mathbb{R}^n \\
\end{align*}
\end{split}\]</div>
<p>Summarizing, the essential difference between training the linear and kernelized SVM is the need to compute and factor the Gram matrix. The result will be a set of non-zero coefficients <span class="math notranslate nohighlight">\(\alpha_i &gt; 0\)</span> the define a set of support vectors <span class="math notranslate nohighlight">\(\mathcal{SV}\)</span>. The classifier is then given by</p>
<div class="math notranslate nohighlight">
\[y^{pred} = \text{sgn} \left( \sum_{i\in\mathcal{SV}} \alpha_iK(\bar{x}_i, \bar{x}) \right)\]</div>
<p>The following cell implements this model, leaving it to the user to specify the kernel function via a lambda-function argument.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">kernelSVMFactory</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">@</span> <span class="n">z</span><span class="p">)):</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="c1"># convert to numpy arrays for speed</span>
    <span class="n">X_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()])</span>
    <span class="n">y_</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

    <span class="c1"># kernel matrix</span>
    <span class="n">G</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[</span><span class="n">y_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">y_</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X_</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:])</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="c1"># spectral factors for a positive semi-definite matrix</span>
    <span class="n">eigvals</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">eigvals</span> <span class="o">&gt;=</span> <span class="n">tol</span> <span class="o">*</span> <span class="nb">max</span><span class="p">(</span><span class="n">eigvals</span><span class="p">)</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">V</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">eigvals</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
    <span class="n">q</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

    <span class="c1"># build model</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">block</span><span class="p">()</span>

    <span class="c1"># decision variables</span>
    <span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span>
    <span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">lb</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">c</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    <span class="n">m</span><span class="o">.</span><span class="n">z</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">variable_list</span><span class="p">([</span><span class="n">pmo</span><span class="o">.</span><span class="n">variable</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">q</span><span class="p">)])</span>

    <span class="c1"># objective</span>
    <span class="n">m</span><span class="o">.</span><span class="n">o</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">expr</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">r</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">))</span>

    <span class="c1"># constraints</span>
    <span class="n">m</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">constraint_list</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">pmo</span><span class="o">.</span><span class="n">constraint</span><span class="p">(</span><span class="n">body</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span><span class="n">F</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">-</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">rhs</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">pmo</span><span class="o">.</span><span class="n">conic</span><span class="o">.</span><span class="n">rotated_quadratic</span><span class="o">.</span><span class="n">as_domain</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>

    <span class="c1"># solve</span>
    <span class="n">SOLVER</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

    <span class="n">y_support</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
        <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]()</span> <span class="o">&gt;</span> <span class="mf">1e-3</span> <span class="o">*</span> <span class="n">c</span> <span class="o">/</span> <span class="n">n</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)],</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">index</span>
    <span class="p">)</span>
    <span class="n">scatter_labeled_data</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">y_support</span><span class="p">,</span>
        <span class="n">colors</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">],</span>
        <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Support Vector&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">],</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Support Vectors&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># get indices of the support vectors</span>
    <span class="n">SV</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]()</span> <span class="o">&gt;</span> <span class="mf">1e-3</span><span class="p">)]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">kernelSVM</span><span class="p">(</span><span class="n">Z</span><span class="p">):</span>
        <span class="n">nz</span><span class="p">,</span> <span class="n">pz</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">Z_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">nz</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Z</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()])</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]()</span> <span class="o">*</span> <span class="n">y_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">Z_</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">SV</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nz</span><span class="p">)</span>
            <span class="p">],</span>
            <span class="n">index</span><span class="o">=</span><span class="n">Z</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">y_pred</span>

    <span class="k">return</span> <span class="n">kernelSVM</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="linear-kernel">
<h3>Linear kernel<a class="headerlink" href="#linear-kernel" title="Link to this heading">#</a></h3>
<p>A linear kernel reduces the kernelized SVM to the previous case.</p>
<div class="math notranslate nohighlight">
\[K(x, z) = x^\top z\]</div>
<p>This is useful for verifying the calculation because we can check if we obtain indeed the same results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm</span> <span class="o">=</span> <span class="n">kernelSVMFactory</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">x</span> <span class="o">@</span> <span class="n">z</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">validate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">scatter_comparison</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matthews correlation coefficient (MCC) = 0.762
Sensitivity =  91.1%
Precision =  90.6%
Accuracy =  88.7%
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Predicted Positive</th>
      <th>Predicted Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actual Positive</th>
      <td>154</td>
      <td>15</td>
    </tr>
    <tr>
      <th>Actual Negative</th>
      <td>16</td>
      <td>90</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../../_images/cdfaf543ebc318e61ba2c1036834b6b90abb7f510d9f864e41848be03660cdfb.png" src="../../_images/cdfaf543ebc318e61ba2c1036834b6b90abb7f510d9f864e41848be03660cdfb.png" />
<img alt="../../_images/0bf54b987bccbd5a0b6f23829b6f0baa0c6faf3d4c34b57513ff8cfd25f41a43.png" src="../../_images/0bf54b987bccbd5a0b6f23829b6f0baa0c6faf3d4c34b57513ff8cfd25f41a43.png" />
<img alt="../../_images/395628573790b57626f1871ddc50548e06838566f987d79d035b753f81f95ec4.png" src="../../_images/395628573790b57626f1871ddc50548e06838566f987d79d035b753f81f95ec4.png" />
</div>
</div>
</section>
<section id="radial-basis-function-kernel">
<h3>Radial basis function kernel<a class="headerlink" href="#radial-basis-function-kernel" title="Link to this heading">#</a></h3>
<p>A radial basis function kernal is given by</p>
<div class="math notranslate nohighlight">
\[K(x, z) = \exp\left(-\gamma \|x - z\|^2\right)\]</div>
<p>The radial basis function is commonly used as the default kernel in SVM applications and as we shall see, it can give a significant boost to the predictive performance of our tool.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rbf</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">kernelSVMFactory</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="n">rbf</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">validate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">scatter_comparison</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matthews correlation coefficient (MCC) = 0.881
Sensitivity =  92.9%
Precision =  97.5%
Accuracy =  94.2%
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Predicted Positive</th>
      <th>Predicted Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actual Positive</th>
      <td>157</td>
      <td>12</td>
    </tr>
    <tr>
      <th>Actual Negative</th>
      <td>4</td>
      <td>102</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../../_images/14f6aa9a793c3dce5bddf3273f053f3e2e1eff087bd31a155b5f3a035566892c.png" src="../../_images/14f6aa9a793c3dce5bddf3273f053f3e2e1eff087bd31a155b5f3a035566892c.png" />
<img alt="../../_images/f7eed3f1b89e6d9ca0f0a1f45b48c6980a0c870e4b56f582c778a56d7c5b5fcd.png" src="../../_images/f7eed3f1b89e6d9ca0f0a1f45b48c6980a0c870e4b56f582c778a56d7c5b5fcd.png" />
<img alt="../../_images/ab22319437c315af48eb165e1911f0c23cc187c91e91e3059a9dc78ce8382586.png" src="../../_images/ab22319437c315af48eb165e1911f0c23cc187c91e91e3059a9dc78ce8382586.png" />
</div>
</div>
</section>
<section id="polynomial-kernel">
<h3>Polynomial kernel<a class="headerlink" href="#polynomial-kernel" title="Link to this heading">#</a></h3>
<p>Another important kernel function type is the polynomial kernel (which corresponds to including in the feature vector the powers of all featurs up to a certain degree <span class="math notranslate nohighlight">\(d\)</span>).
$<span class="math notranslate nohighlight">\(K(x, z) = (1 + x^\top z)^d\)</span><span class="math notranslate nohighlight">\(
Again, the higher the value of \)</span>d<span class="math notranslate nohighlight">\(, the more predictive power we can expect from the corresponding SVM, therefore, we encourage you to try this formulation varying \)</span>d$.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">poly</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span> <span class="o">@</span> <span class="n">z</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>

<span class="n">svm</span> <span class="o">=</span> <span class="n">kernelSVMFactory</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="n">poly</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">svm</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">validate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">scatter_comparison</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matthews correlation coefficient (MCC) = 0.438
Sensitivity =  47.3%
Precision =  93.0%
Accuracy =  65.5%
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Predicted Positive</th>
      <th>Predicted Negative</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Actual Positive</th>
      <td>80</td>
      <td>89</td>
    </tr>
    <tr>
      <th>Actual Negative</th>
      <td>6</td>
      <td>100</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../../_images/fe0215308b80c81228506c7606f11f53544e2ddac740f197b97c9cf6f3208967.png" src="../../_images/fe0215308b80c81228506c7606f11f53544e2ddac740f197b97c9cf6f3208967.png" />
<img alt="../../_images/88a68c8f0f320ed83cf060f0adc5117b83dcb7e464e6d80cc4c60705b5be0176.png" src="../../_images/88a68c8f0f320ed83cf060f0adc5117b83dcb7e464e6d80cc4c60705b5be0176.png" />
<img alt="../../_images/3447e84d377ad7f46e4e9ca00bf48da96b620a0928e3e9e34b82625357dec810.png" src="../../_images/3447e84d377ad7f46e4e9ca00bf48da96b620a0928e3e9e34b82625357dec810.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks/06"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="04-building-insulation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">6.4 Optimal Design of Multilayered Building Insulation</p>
      </div>
    </a>
    <a class="right-next"
       href="06-investment-wheel.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Extra material: Luenberger’s Investment Wheel</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preamble-install-pyomo-and-a-solver">Preamble: Install Pyomo and a solver</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-data-set">The Data Set</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#read-data">Read data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#select-features-and-training-sets">Select features and training sets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-metrics">Performance metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conic-optimization-model">Conic optimization model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#primal-formulation">Primal formulation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dual-formulation">Dual formulation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pyomo-implementation">Pyomo implementation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kernelized-svm">Kernelized SVM</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nonlinear-feature-spaces">Nonlinear feature spaces</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-kernel-trick">The kernel trick</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-kernel">Linear kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#radial-basis-function-kernel">Radial basis function kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-kernel">Polynomial kernel</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The MO Book Group
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>